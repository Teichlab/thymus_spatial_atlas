{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invisible-penny",
   "metadata": {},
   "source": [
    "# Build neighbourhood VDJ feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-owner",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import dandelion as ddl\n",
    "import palantir\n",
    "import scipy as sp\n",
    "ddl.logging.print_header()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sc.settings.set_figure_params(dpi = 160, color_map = 'RdYlBu_r', dpi_save = 300, format = 'pdf')\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### need to add this line to restore plotting function of scanpy in the presence of palantir\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-dance",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object loaded with abTCR\n",
    "adata_abtcr = sc.read('Thymus_Atlas_v13_abTCR.h5ad')\n",
    "adata_abtcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "adata_abtcr.obs['annotation_level_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up subsets and colors\n",
    "ct_order = ['T_DN(early)','T_DN(P)','T_DN(Q)','T_DN(CD25)','T_DP(P)-1','T_DP(P)-2','T_DP(P)-3','T_DP(P)-4','T_DP(Q)','T_DP(Q)-HSPH1','T_DP(Q)-CD99','T_αβT(entry)','T_CD4','T_CD8','T_CD8-Prolif']\n",
    "ct_color_map = dict(zip(ct_order, np.array(sns.color_palette('tab20'))[range(len(ct_order))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-proceeding",
   "metadata": {},
   "source": [
    "# Filter cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-enemy",
   "metadata": {},
   "source": [
    "### Subset cells to DP onwards, and cells with paired TCRab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to setup the data to only contain cells with VDJ info.\n",
    "bdata = ddl.tl.setup_vdj_pseudobulk(adata_abtcr, \n",
    "                                    mode='abT',\n",
    "                                    subsetby='annotation_level_3', \n",
    "                                    groups = ct_order, \n",
    "                                    productive_vdj=False, \n",
    "                                    productive_vj=False,\n",
    "                                    check_vdj_mapping=None,\n",
    "                                    check_vj_mapping=None,\n",
    "                                   #filter_pattern = None,\n",
    "                                   #allowed_chain_status=None\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata.obs['j_call_abT_VDJ_main'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all entries with ',' (inconfident mappings) to 'None'\n",
    "for chain in ['v_call_abT_VDJ_main', 'j_call_abT_VDJ_main','v_call_abT_VJ_main', 'j_call_abT_VJ_main']:\n",
    "    bdata.obs[chain] = bdata.obs[chain].astype('object')\n",
    "    for cell in bdata.obs_names:\n",
    "        gene = bdata.obs.loc[cell, chain]\n",
    "        if ',' in gene or gene =='None' or gene =='No_contig':\n",
    "            bdata.obs.loc[cell, chain] = chain+'_None'\n",
    "    bdata.obs[chain] = bdata.obs[chain].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one cell that has TRBJ2-7 in j_call_abT_VJ_main\n",
    "bdata = bdata[~(bdata.obs['j_call_abT_VJ_main']=='TRBJ2-7')]\n",
    "bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata.write('Thymus_Atlas_v13_abTCR_filetered.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-happening",
   "metadata": {},
   "source": [
    "# Select neighbourhoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-integer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## need to redo neighborhood graph after subsetting cells before milo\n",
    "# n_neighbors decides the minimum neighbourhood size \n",
    "# here use_rep = 'X_scvi' as data integration was done using scVI\n",
    "sc.pp.neighbors(bdata, use_rep = \"X_scVI\", n_neighbors = 50)\n",
    "sc.tl.umap(bdata, random_state = 1712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-genius",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take a look at the UMAP to make sure it looks reasonable i.e. different cell types are clustered separately\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [5.5,5]\n",
    "sc.pl.umap(bdata, color=['annotation_level_3'], palette = ct_color_map, legend_loc = 'on data', legend_fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata.obs['annotation_level_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-orientation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import milopy\n",
    "import milopy.core as milo\n",
    "\n",
    "# use milo to sample neighbourhood\n",
    "milo.make_nhoods(bdata)\n",
    "# build neighbourhood adata in bdata.uns['nhood_adata']\n",
    "milo.count_nhoods(bdata, sample_col='sample') # this step is needed to build bdata.uns['nhood_adata'] and sample_col can be anything\n",
    "# this step is needed for plotting below\n",
    "milopy.utils.build_nhood_graph(bdata)\n",
    "# assign neighbourhood celltype by majority voting\n",
    "# results are in bdata.uns['nhood_adata'].obs['nhood_annotation'] & bdata.uns['nhood_adata'].obs['nhood_annotation_frac'] \n",
    "milopy.utils.annotate_nhoods(bdata, anno_col='annotation_level_3')\n",
    "bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram to look at neighbourhood sizes ### optional\n",
    "plt.rcParams[\"figure.figsize\"] = [4,4]\n",
    "plt.hist(np.array(bdata.obsm[\"nhoods\"].sum(0)).flatten(), bins=50);\n",
    "plt.title('neighborhood sizes')\n",
    "plt.xlabel('number of cells in the neighborhood')\n",
    "plt.ylabel('proportion (%) of neighborhoods')\n",
    "#plt.savefig(fig_path+'TCR_neighbourhood_size.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-remedy",
   "metadata": {},
   "source": [
    "Now neighbourhood adata is stored in bdata.uns['nhood_adata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata.uns['nhood_adata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bdata.obs[['v_call_abT_VDJ_main', 'j_call_abT_VDJ_main','v_call_abT_VJ_main', 'j_call_abT_VJ_main']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(tmp.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-assumption",
   "metadata": {},
   "source": [
    "# Create neighbourhood VDJ feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from typing import List, Optional, Union\n",
    "import scipy as sp\n",
    "def _get_pbs(pbs, obs_to_bulk, adata):\n",
    "    \"\"\"\n",
    "    Helper function to ensure we have a cells by pseudobulks matrix which we can use for\n",
    "    pseudobulking. Uses the pbs and obs_to_bulk inputs to vdj_pseudobulk() and\n",
    "    gex_pseudobulk().\n",
    "    \"\"\"\n",
    "    # well, we need some way to pseudobulk\n",
    "    if pbs is None and obs_to_bulk is None:\n",
    "        raise ValueError(\n",
    "            \"You need to specify `pbs` or `obs_to_bulk` when calling the function\"\n",
    "        )\n",
    "\n",
    "    # but just one\n",
    "    if pbs is not None and obs_to_bulk is not None:\n",
    "        raise ValueError(\"You need to specify `pbs` or `obs_to_bulk`, not both\")\n",
    "\n",
    "    # turn the pseubodulk matrix dense if need be\n",
    "    if pbs is not None:\n",
    "        if sp.sparse.issparse(pbs):\n",
    "            pbs = pbs.todense()\n",
    "\n",
    "    # get the obs-derived pseudobulk\n",
    "    if obs_to_bulk is not None:\n",
    "        if type(obs_to_bulk) is list:\n",
    "            # this will create a single value by pasting all the columns together\n",
    "            tobulk = adata.obs[obs_to_bulk].T.astype(str).agg(\",\".join)\n",
    "        else:\n",
    "            # we just have a single column\n",
    "            tobulk = adata.obs[obs_to_bulk]\n",
    "        # this pandas function creates the exact pseudobulk assignment we want\n",
    "        # this needs to be different than the default uint8\n",
    "        # as you can have more than 255 cells in a pseudobulk, it turns out\n",
    "        pbs = pd.get_dummies(tobulk, dtype=\"uint16\").values\n",
    "    return pbs\n",
    "def _get_pbs_obs(pbs, obs_to_take, adata):\n",
    "    \"\"\"\n",
    "    Helper function to create the pseudobulk object's obs. Uses the pbs and obs_to_take\n",
    "    inputs to vdj_pseudobulk() and gex_pseudobulk().\n",
    "    \"\"\"\n",
    "    # prepare per-pseudobulk calls of specified metadata columns\n",
    "    pbs_obs = pd.DataFrame(index=np.arange(pbs.shape[1]))\n",
    "    if obs_to_take is not None:\n",
    "        # just in case a single is passed as a string\n",
    "        if type(obs_to_take) is not list:\n",
    "            obs_to_take = [obs_to_take]\n",
    "        # now we can iterate over this nicely\n",
    "        # using the logic of milopy's annotate_nhoods()\n",
    "        for anno_col in obs_to_take:\n",
    "            anno_dummies = pd.get_dummies(adata.obs[anno_col])\n",
    "            # this needs to be turned to a matrix so dimensions get broadcast correctly\n",
    "            anno_count = np.asmatrix(pbs).T.dot(anno_dummies.values)\n",
    "            anno_frac = np.array(anno_count / anno_count.sum(1))\n",
    "            anno_frac = pd.DataFrame(\n",
    "                anno_frac,\n",
    "                index=np.arange(pbs.shape[1]),\n",
    "                columns=anno_dummies.columns,\n",
    "            )\n",
    "            pbs_obs[anno_col] = anno_frac.idxmax(1)\n",
    "            pbs_obs[anno_col + \"_fraction\"] = anno_frac.max(1)\n",
    "    # report the number of cells for each pseudobulk\n",
    "    # ensure pbs is an array so that it sums into a vector that can go in easily\n",
    "    pbs_obs[\"cell_count\"] = np.sum(np.asarray(pbs), axis=0)\n",
    "    return pbs_obs\n",
    "\n",
    "def vdj_pseudobulk(\n",
    "    adata: AnnData,\n",
    "    pbs: Optional[Union[np.ndarray, sp.sparse.csr_matrix]] = None,\n",
    "    obs_to_bulk: Optional[Union[str, List[str]]] = None,\n",
    "    obs_to_take: Optional[Union[str, List[str]]] = None,\n",
    "    cols: Optional[List[str]] = None,\n",
    ") -> AnnData:\n",
    "    \"\"\"Function for making pseudobulk vdj feature space. One of `pbs` or `obs_to_bulk`\n",
    "    needs to be specified when calling.\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        Cell adata, preferably after `ddl.tl.setup_vdj_pseudobulk()`\n",
    "    pbs : Optional[Union[np.ndarray, sp.sparse.csr_matrix]], optional\n",
    "        Optional binary matrix with cells as rows and pseudobulk groups as columns\n",
    "    obs_to_bulk : Optional[Union[str, List[str]]], optional\n",
    "        Optional obs column(s) to group pseudobulks into; if multiple are provided, they\n",
    "        will be combined\n",
    "    obs_to_take : Optional[Union[str, List[str]]], optional\n",
    "        Optional obs column(s) to identify the most common value of for each pseudobulk.\n",
    "    cols : Optional[List[str]], optional\n",
    "        If provided, use the specified obs columns to extract V(D)J calls\n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "        pb_adata, whereby each observation is a pseudobulk:\\n\n",
    "        VDJ usage frequency stored in pb_adata.X\\n\n",
    "        VDJ genes stored in pb_adata.var\\n\n",
    "        pseudobulk metadata stored in pb_adata.obs\\n\n",
    "        pseudobulk assignment (binary matrix with input cells as columns) stored in pb_adata.obsm['pbs']\\n\n",
    "    \"\"\"\n",
    "    # get our cells by pseudobulks matrix\n",
    "    pbs = _get_pbs(pbs, obs_to_bulk, adata)\n",
    "\n",
    "    # if not specified by the user, use the following default dandelion VJ columns\n",
    "    if cols is None:\n",
    "        cols = [i for i in adata.obs if re.search(\"_VDJ_main|_VJ_main\", i)]\n",
    "\n",
    "    # perform matrix multiplication of pseudobulks by cells matrix by a cells by VJs matrix\n",
    "    # start off by creating the cell by VJs matrix, using the pandas dummies again\n",
    "    # skip the prefix stuff as the VJ genes will be unique in the columns\n",
    "    vjs = pd.get_dummies(adata.obs[cols], prefix=\"\", prefix_sep=\"\")\n",
    "    # TODO: DENAN SOMEHOW? AS IN NAN GENES?\n",
    "    # can now multiply transposed pseudobulk assignments by this vjs thing, turn to df\n",
    "    vj_pb_count = pbs.T.dot(vjs.values)\n",
    "    df = pd.DataFrame(\n",
    "        vj_pb_count, index=np.arange(pbs.shape[1]), columns=vjs.columns\n",
    "    )\n",
    "\n",
    "    # loop over V(D)J gene categories\n",
    "    #for col in cols:\n",
    "        # identify columns holding genes belonging to the category\n",
    "        # and then normalise the values to 1 for each pseudobulk\n",
    "        #mask = np.isin(df.columns, np.unique(adata.obs[col]))\n",
    "        #df.loc[:, mask] = df.loc[:, mask].div(\n",
    "            #df.loc[:, mask].sum(axis=1), axis=0\n",
    "        #)\n",
    "\n",
    "    # create obs for the new pseudobulk object\n",
    "    pbs_obs = _get_pbs_obs(pbs, obs_to_take, adata)\n",
    "\n",
    "    # store our feature space and derived metadata into an AnnData\n",
    "    pb_adata = sc.AnnData(\n",
    "        np.array(df), var=pd.DataFrame(index=df.columns), obs=pbs_obs\n",
    "    )\n",
    "    # store the pseudobulk assignments, as a sparse for storage efficiency\n",
    "    # transpose as the original matrix is cells x pseudobulks\n",
    "    pb_adata.obsm[\"pbs\"] = sp.sparse.csr_matrix(pbs.T)\n",
    "    return pb_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-weather",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function for making neighbourhood vdj feature space\n",
    "nhood_adata = vdj_pseudobulk(bdata, pbs = bdata.obsm['nhoods'], obs_to_take = 'annotation_level_3', cols=['v_call_abT_VDJ_main', 'j_call_abT_VDJ_main','v_call_abT_VJ_main', 'j_call_abT_VJ_main'])\n",
    "nhood_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncell = nhood_adata.shape[0]\n",
    "nhood_size = nhood_adata.obs['cell_count']\n",
    "cols=['v_call_abT_VDJ_main', 'j_call_abT_VDJ_main','v_call_abT_VJ_main', 'j_call_abT_VJ_main']\n",
    "for col in cols:\n",
    "    mask = np.isin(nhood_adata.var_names, np.unique(bdata.obs[col]))\n",
    "    \n",
    "    # normalise including None\n",
    "    genes = nhood_adata.var_names[mask]\n",
    "    df = pd.DataFrame(data = nhood_adata[:,genes].X.copy(), columns = genes)\n",
    "    df = df / np.array(np.sum(df, axis=1)).reshape(ncell,1) # this is the same as /nhood_adata.obs['cell_count']\n",
    "\n",
    "    # normalise excluding None \n",
    "    genes2 = [gene for gene in genes if gene != col+'_None']\n",
    "    df2 = pd.DataFrame(data = nhood_adata[:,genes2].X.copy(), columns = genes2)\n",
    "    df2 = df2 / np.array(np.sum(df2, axis=1)).reshape(ncell,1)\n",
    "    # if expressing cell number < 10, then everything in df2 set to 0\n",
    "    nhood_select = np.array(nhood_size) * np.array(1-df[col+'_None']) < 10\n",
    "    df2.loc[nhood_select, :] = 0\n",
    "    \n",
    "    # combine dataframe and replace .X with normalised data\n",
    "    df_combine = pd.concat([df2, df[col+'_None']], axis=1)\n",
    "    nhood_adata[:,df_combine.columns].X = df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan with 0 (as e.g. one neighborhood doesn't have any TRBV, then it would be nan for all TRBV genes, but 1 for v_call_abT_VDJ_main_None)\n",
    "nhood_adata.X = np.nan_to_num(nhood_adata.X, copy=True, nan=0, posinf=None, neginf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-scene",
   "metadata": {},
   "source": [
    "     nhood_adata is the new neighbourhood VDJ feature space, whereby each observation is a cell neighbourhood\n",
    "     VDJ usage frequency stored in nhood_adata.X\n",
    "     VDJ genes stored in nhood_adata.var\n",
    "     neighbourhood metadata stored in nhood_adata.obs\n",
    "     can visualise the data using PCA or UMAP (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort out the annotation colour order\n",
    "nhood_adata.obs['annotation_level_3'] = nhood_adata.obs['annotation_level_3'].astype('category')\n",
    "nhood_adata.obs['annotation_level_3'] = nhood_adata.obs['annotation_level_3'].cat.reorder_categories(ct_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-packet",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.pp.pca(nhood_adata, random_state = 1712)\n",
    "sc.pl.pca(nhood_adata, color=['anno_lvl_2_final_clean'], palette=ct_color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-tours",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(nhood_adata, random_state = 1712)\n",
    "sc.tl.umap(nhood_adata, random_state = 1712)\n",
    "sc.pl.umap(nhood_adata, color=['anno_lvl_2_final_clean'], palette=ct_color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-track",
   "metadata": {},
   "source": [
    "### Run Pseudotime on VDJ feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you install palantir if you don't already have it\n",
    "\n",
    "# Run diffusion maps\n",
    "pca_projections = pd.DataFrame(nhood_adata.obsm['X_pca'], index=nhood_adata.obs_names)\n",
    "dm_res = palantir.utils.run_diffusion_maps(pca_projections, n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(10), dm_res['EigenValues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_data = palantir.utils.determine_multiscale_space(dm_res, n_eigs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [4,4]\n",
    "sc.pl.umap(nhood_adata, color=[col + '_None' for col in cols],color_map = 'RdYlBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the start and end points\n",
    "# start\n",
    "#tmp = nhood_adata[nhood_adata.obs['anno_lvl_2_final_clean'] == 'DP(P)_T']\n",
    "tmp = nhood_adata[nhood_adata.obs['anno_lvl_2_final_clean'] == 'DN(early)_T']\n",
    "rootcell = np.argmax(tmp.obsm['X_umap'][:,1])\n",
    "rootcell = tmp.obs_names[rootcell]\n",
    "nhood_adata.obs['rootcell'] = 0\n",
    "nhood_adata.obs.loc[rootcell,'rootcell'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ends\n",
    "tmp1 = nhood_adata[nhood_adata.obs['anno_lvl_2_final_clean'] == 'CD8+T']\n",
    "tmp2 = nhood_adata[nhood_adata.obs['anno_lvl_2_final_clean'] == 'CD4+T']\n",
    "endcell1 = np.argmax(tmp1.obsm['X_umap'][:,0])\n",
    "endcell1 = tmp1.obs_names[endcell1]\n",
    "endcell2 = np.argmin(tmp2.obsm['X_umap'][:,0])\n",
    "endcell2 = tmp2.obs_names[endcell2]\n",
    "\n",
    "terminal_states = pd.Series(['CD8+T', 'CD4+T'], \n",
    "                           index=[endcell1,endcell2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rootcell and terminal states\n",
    "nhood_adata.obs['terminal_states'] = 0\n",
    "nhood_adata.obs.loc[terminal_states.index, 'terminal_states'] = 1\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "sc.pl.umap(nhood_adata,color=['rootcell','terminal_states','anno_lvl_2_final_clean'],\n",
    "           title=['root cell','terminal states','nhood annotation'],color_map='OrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_res = palantir.core.run_palantir(ms_data,  rootcell, num_waypoints=500, \n",
    "                                    terminal_states = terminal_states.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_res.branch_probs.columns = terminal_states[pr_res.branch_probs.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-prescription",
   "metadata": {},
   "source": [
    "## Visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.pseudotime_transfer(adata = nhood_adata, pr_res = pr_res, suffix = '_nhood_vdj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [4,4]\n",
    "plot = ['pseudotime', 'prob_CD8+T', 'prob_CD4+T']\n",
    "sc.pl.umap(nhood_adata,color=[term + '_nhood_vdj' for term in plot],\n",
    "           title=['pseudotime','branch probability to CD8+T',\n",
    "                  'branch probability to CD4+T'],\n",
    "           frameon=False,wspace=0.1,\n",
    "           color_map = 'RdYlBu_r'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-words",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
